<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2019-08-23">

<title>Zach Mueller - Capstone Project - Revisiting IMDB</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-99XP3R051T"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-99XP3R051T', { 'anonymize_ip': true});
</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Zach Mueller</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../blog/index.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../til/index.html" rel="" target="">
 <span class="menu-text">Today I Learned</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/muellerzr" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/TheZachMueller" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Capstone Project - Revisiting IMDB</li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#overall-how-it-works" id="toc-overall-how-it-works" class="nav-link active" data-scroll-target="#overall-how-it-works">Overall How it Works</a></li>
  <li><a href="#whats-new" id="toc-whats-new" class="nav-link" data-scroll-target="#whats-new">What’s New?</a>
  <ul class="collapse">
  <li><a href="#backwards" id="toc-backwards" class="nav-link" data-scroll-target="#backwards">Backwards</a></li>
  <li><a href="#tokenization" id="toc-tokenization" class="nav-link" data-scroll-target="#tokenization">Tokenization</a></li>
  </ul></li>
  <li><a href="#the-capstone-project" id="toc-the-capstone-project" class="nav-link" data-scroll-target="#the-capstone-project">The Capstone Project</a>
  <ul class="collapse">
  <li><a href="#the-language-model" id="toc-the-language-model" class="nav-link" data-scroll-target="#the-language-model">The Language Model</a></li>
  <li><a href="#the-classifier" id="toc-the-classifier" class="nav-link" data-scroll-target="#the-classifier">The Classifier</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a></li>
  <li><a href="#closing-thoughts" id="toc-closing-thoughts" class="nav-link" data-scroll-target="#closing-thoughts">Closing Thoughts</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Capstone Project - Revisiting IMDB</h1>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">August 23, 2019</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p>Very recently, Rachel Thomas and Jeremy Howard released a new course focused on Natural Language Processing. I had stated previously in my blogs I wanted to document my progress and come up with a “Capstone” project for the course. I have been quiet these past few weeks due to my busy schedule, and I have not had the time to really focus on these blogs. As such, here is the capstone project, along with where the new NLP course fits in, and what those practices are.</p>
<section id="overall-how-it-works" class="level2">
<h2 class="anchored" data-anchor-id="overall-how-it-works">Overall How it Works</h2>
<p>For those unfamiliar with the methodology, fastai popularized and engineered the <a href="[https://arxiv.org/abs/1801.06146](https://arxiv.org/abs/1801.06146)">ULM-FiT</a> model, or Universal Language Model Fine-tuning. In it, we first train a language model that is pre-trained on our initial language. In our case, this looks like the following:<br>
- Take an English model trained on WikiText103 - Train this model further on our corpus (our overall language) - Use that model as an embedding for the classification model</p>
<p>This is how our general overview for our training will do, with a few exceptions. We will be training the language model on everything we have available to use. In terms of IMDB, there is a folder with more than twice the amount of data for unsupervised text.</p>
</section>
<section id="whats-new" class="level2">
<h2 class="anchored" data-anchor-id="whats-new">What’s New?</h2>
<section id="backwards" class="level3">
<h3 class="anchored" data-anchor-id="backwards">Backwards</h3>
<p>The first new state-of-the-art practice that was taught in the course is backwards models. Essentially the language model learns from backwards word orders. For example, take the following sentence: “He went to the beach.” Our new language model would instead be fed: “beach the to went He” (after tokenization and other data preparation). What Jeremy described we could do from here is something called an ensemble, where we take two different models that were trained for the same task, average their predictions, and we can generally perform <em>better</em> than either one individually.</p>
<p>To utilize this feature, when we create a databunch we include <code>backwards=True</code> the following for both our language databunch and the classifier databunch:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> (TextList.from_folder(path)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>        .split_by_rand_pct(<span class="fl">0.1</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>        .label_for_lm()</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>        .databunch(bs<span class="op">=</span><span class="dv">128</span>, num_workers<span class="op">=</span><span class="dv">4</span>, backwards<span class="op">=</span><span class="va">True</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="tokenization" class="level3">
<h3 class="anchored" data-anchor-id="tokenization">Tokenization</h3>
<p>Along with a new model to train, Jeremy and the folks at fastai integrated SentencePiece into the library. Before, fastai only supported Spacy tokenization and so this was the benchmark used for the IMDB Movie Review sentiment analysis problem. To utilize this, we need to first be on the most recent version of the fastai library.</p>
<p>When we want to declare a tokenizer, we add it to that initial <code>TextList.from_</code> call as a processor. For example, here is what Spacy’s tokenization looks like (it is used automatically if nothing is passed in):</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> Tokenizer(SpaceTokenizer, <span class="st">'en'</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>processor <span class="op">=</span> [TokenizeProcessor(tokenizer<span class="op">=</span>tokenizer), </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>             NumericalizeProcessor(max_vocab<span class="op">=</span><span class="dv">30000</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This creates a processor that will tokenize our items and then numericalize each of those, or map each token to a number.</p>
<p>To use SentencePiece, it is a quick one-liner, plus OpenFileProcessor (used to read in the text from files):</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>processor <span class="op">=</span> [OpenFileProcessor(), SPProcessor()]</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> (TextList.from_folder(path, processor<span class="op">=</span>processor)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        .split_by_rand_pct(<span class="fl">0.1</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        .label_for_lm()</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        .databunch(bs<span class="op">=</span><span class="dv">128</span>, num_workers<span class="op">=</span><span class="dv">4</span>, backwards<span class="op">=</span><span class="va">True</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>And now we are using SentencePiece!</p>
</section>
</section>
<section id="the-capstone-project" class="level2">
<h2 class="anchored" data-anchor-id="the-capstone-project">The Capstone Project</h2>
<p>The project itself is based on an idea Jeremy discussed in the lectures: what if someone were to try to utilize an ensemble of both a fowards and backwards model, trained twice on both SentencePiece and on Spacy. His theory is that there could be very-close-to-if-not state of the art results. So that is our goal. We will create four models, utilizing both tokenizers and model-functionalities.</p>
<section id="the-language-model" class="level3">
<h3 class="anchored" data-anchor-id="the-language-model">The Language Model</h3>
<p>For the langauge model, here is how the four databunches were generated: (for nomenclature sake, each databunch and model will have the following: x_y_z_a where x is either data or learn, y is either lm or cls, z is either spy or spp, and a is either forwards or backwards)</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>data_lm_spp_fwd <span class="op">=</span> (TextList.from_folder(path, processor<span class="op">=</span>[OpenFileProcessor(), SPProcessor()])</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>                  .split_by_rand_pct(<span class="fl">0.1</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>                  .label_for_lm()</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>                  .databunch(bs<span class="op">=</span><span class="dv">128</span>, num_workers<span class="op">=</span><span class="dv">4</span>, backwards<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>                  </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>data_lm_spp_bwd <span class="op">=</span> (TextList.from_folder(path, processor<span class="op">=</span>[OpenFileProcessor(), SPProcessor()])</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>                  .split_by_rand_pct(<span class="fl">0.1</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>                  .label_for_lm()</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>                  .databunch(bs<span class="op">=</span><span class="dv">128</span>, num_workers<span class="op">=</span><span class="dv">4</span>, backwards<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>data_lm_spy_fwd <span class="op">=</span> (TextList.from_folder(path)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>                  .split_by_rand_pct(<span class="fl">0.1</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>                  .label_for_lm()</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>                  .databunch(bs<span class="op">=</span><span class="dv">64</span>, num_workers<span class="op">=</span><span class="dv">4</span>, backwards<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>data_lm_spy_bwd <span class="op">=</span> (TextList.from_folder(path)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>                  .split_by_rand_pct(<span class="fl">0.1</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>                  .label_for_lm()</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>                  .databunch(bs<span class="op">=</span><span class="dv">64</span>, num_workers<span class="op">=</span><span class="dv">4</span>, backwards<span class="op">=</span><span class="va">True</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>One thing to note here is the batch size difference. When I trained on my 1060, I noticed that I could push double the batches using SentencePiece than with Spacy, leading me to believe it is more efficient GPU wise.</p>
<p>From here, I generated our typical learners while also utilizing Mixed Precision to help get the most out of my CUDA cores. This has been seen to reduce training time astronomically in some cases, especially with language models. We can apply this to our models with <code>to_fp16()</code></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>learn_lm_spy_fwd <span class="op">=</span> language_model_learner(data_lm_spy_fwd, AWD_LSTM, drop_mult<span class="op">=</span><span class="fl">1.</span>).to_fp16()</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>learn_lm_spy_bwd <span class="op">=</span> language_model_learner(data_lm_spy_bwd, AWD_LSTM, drop_mult<span class="op">=</span><span class="fl">1.</span>).to_fp16()</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>learn_lm_spp_fwd <span class="op">=</span> language_model_learner(data_lm_spp_fwd, AWD_LSTM, drop_mult<span class="op">=</span><span class="fl">1.</span>).to_fp16()</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>learn_lm_spp_bwd <span class="op">=</span> language_model_learner(data_lm_spp_bwd, AWD_LSTM, drop_mult<span class="op">=</span><span class="fl">1.</span>).to_fp16()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>From here, each model was trained in the same fashion using the following function:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_spy(models:<span class="bu">list</span>):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    names <span class="op">=</span> [<span class="st">'fwd'</span>, <span class="st">'bwd'</span>]</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> model <span class="kw">in</span> models:</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        lr <span class="op">=</span> <span class="fl">1e-2</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        lr <span class="op">*=</span> <span class="dv">64</span><span class="op">/</span><span class="dv">48</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        model.fit_one_cycle(<span class="dv">1</span>, lr, moms<span class="op">=</span>(<span class="fl">0.8</span>,<span class="fl">0.7</span>))</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        model.unfreeze()</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        model.fit_one_cycle(<span class="dv">10</span>, lr<span class="op">/</span><span class="dv">10</span>, moms<span class="op">=</span>(<span class="fl">0.8</span>,<span class="fl">0.7</span>))</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        model.save(<span class="ss">f'spp_</span><span class="sc">{</span>names[x]<span class="sc">}</span><span class="ss">_fine_tuned_10'</span>)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>        model.save_encoder(<span class="ss">f'spp_</span><span class="sc">{</span>names[x]<span class="sc">}</span><span class="ss">_fine_tuned_enc_10'</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> models</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Each language model was trained for 11 epochs, with each achieving roughly 33% by the end. Jeremy’s rule of thumb for language models is regardless of the original language, if you have 30%, you’re good to move on.</p>
<p>One small note, when I tested this initially with IMDB_SAMPLE, I found that I could not get the language model with SentencePiece to fully train for a large number of epochs when compared to Spacy, whereas the full dataset I saw little differentiation. I believe SentencePiece needs more data as a minimum to train on than Spacy.</p>
<p>For every language model, after 11 epochs their accuracy was 33.93%.</p>
<p>The Spacy epochs were each an average of 21:39 minutes, whereas the SentencePiece epochs were an average of 11:04 minutes.</p>
</section>
<section id="the-classifier" class="level3">
<h3 class="anchored" data-anchor-id="the-classifier">The Classifier</h3>
<p>Now for the main tasks at hand, building the sentiment analysis classifier. Here I wound up having GPU memory issues, which lead to a much longer training time, and I also could not get <code>to_fp16()</code> to work, so I could not take advantage of Mixed Precision.</p>
<p>Each model had a batch size of 8 and was trained for 5 epochs total, with an initial learning rate of 2e-2, before degrading from there using the following function:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> []</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>targs <span class="op">=</span> []</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> learn <span class="kw">in</span> learns:</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    learn.fit_one_cycle(<span class="dv">1</span>, lr, moms<span class="op">=</span>(<span class="fl">0.8</span>,<span class="fl">0.7</span>))</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    learn.freeze_to(<span class="op">-</span><span class="dv">2</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    learn.fit_one_cycle(<span class="dv">1</span>, <span class="bu">slice</span>(lr<span class="op">/</span>(<span class="fl">2.6</span><span class="op">**</span><span class="dv">4</span>), lr), moms<span class="op">=</span>(<span class="fl">0.8</span>,<span class="fl">0.7</span>))</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    learn.freeze_to(<span class="op">-</span><span class="dv">3</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    learn.fit_one_cycle(<span class="dv">1</span>, <span class="bu">slice</span>(lr<span class="op">/</span><span class="dv">2</span><span class="op">/</span>(<span class="fl">2.6</span><span class="op">**</span><span class="dv">4</span>), lr<span class="op">/</span><span class="dv">2</span>), moms<span class="op">=</span>(<span class="fl">0.8</span>,<span class="fl">0.7</span>))</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    learn.unfreeze()</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    learn.fit_one_cycle(<span class="dv">2</span>, <span class="bu">slice</span>(lr<span class="op">/</span><span class="dv">10</span><span class="op">/</span>(<span class="fl">2.6</span><span class="op">**</span><span class="dv">4</span>), lr<span class="op">/</span><span class="dv">10</span>), moms<span class="op">=</span>(<span class="fl">0.8</span>,<span class="fl">0.7</span>))</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    preds, targ <span class="op">=</span> learn.get_preds(ordered<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    res.append(preds)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    targs.append(targ)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>To gather the results of the ensemble, I took the raw predictions and averaged them all:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>preds_avg <span class="op">=</span> (res[<span class="dv">0</span>] <span class="op">+</span> res[<span class="dv">1</span>] <span class="op">+</span> res[<span class="dv">2</span>] <span class="op">+</span> res[<span class="dv">3</span>])<span class="op">/</span><span class="dv">4</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>accuracy(preds_avg, targs[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This ensembled accuracy was <strong>94.94%</strong>. Jeremy et al’s paper shows they achieved 95% accuracy, so we did not quite achieve what they got but we were close. But let’s consider it from a different standpoint. How much improvement was adding the SentencePiece and the forwards and backwards models together? The table below compares those results:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"><strong>Name</strong></th>
<th style="text-align: center;"><strong>Accuracy</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Spacy Forward</td>
<td style="text-align: center;">94.49%</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>Spacy Forward and Backwards</strong></td>
<td style="text-align: center;"><strong>94.77%</strong></td>
</tr>
<tr class="odd">
<td style="text-align: center;">SentencePiece Forward</td>
<td style="text-align: center;">94.55%</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>SentencePiece Forward and Backwards</strong></td>
<td style="text-align: center;"><strong>94.66%</strong></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Spacy and SentencePiece Forward</td>
<td style="text-align: center;">94.86%</td>
</tr>
<tr class="even">
<td style="text-align: center;">Spacy and SentencePiece Backwards</td>
<td style="text-align: center;">94.79%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Spacy Forward and Backward and SentencePiece Forward</td>
<td style="text-align: center;">94.89%</td>
</tr>
<tr class="even">
<td style="text-align: center;">Spacy Forward and Backward and SentencePiece Backwards</td>
<td style="text-align: center;">94.88%</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><strong>Spacy and SentencePiece Forward and Backwards</strong></td>
<td style="text-align: center;"><strong>94.94%</strong></td>
</tr>
</tbody>
</table>
<p>So now let’s compare. We can see that compared to the test of a Spacy Model alone forwards and backwards, a SentencePiece model is pretty close, achieving 1/10th of a percent below. But when we start ensembling the various models together, we saw an improvement of 0.17%. While this may seem negligible, think of an error rate in a realistic scope. For every 1,000 reviews, we classify 17 more correctly now.</p>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>First, I know this can be further improved. Jeremy et al’s paper shows they achieved 95% accuracy with Spacy, something I could not quite match. I believe I’m missing something and I need to look at what.</p>
<p>Second, while the results seem negligibly better, I believe they are telling. I tried comparing when either the forwards or the backwards model was there as well, and there was a stark increase in accuracy when comparing them, putting merit to the thought this setup can achieve a new state of the art.</p>
<p>I want to revisit this after some talk on the fastai forums as to exactly what I may be missing within my training when compared with the paper and run again.</p>
<p>All the source code is available at my Github <a href="https://github.com/muellerzr/fastai-Experiments-and-tips">here</a></p>
<p>Thanks for reading!</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>